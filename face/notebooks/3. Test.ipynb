{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "linear-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ipynb.fs.full.GenerateLogs import generate_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "radical-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 24517 images of 6743 different people\n"
     ]
    }
   ],
   "source": [
    "# Return ids of images in each dataset as a list\n",
    "def retrive_ids(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        ids = file.read().split()\n",
    "    return ids\n",
    "\n",
    "data_path = '../data/'\n",
    "names_path = lambda dataset_name: '%s%s-names.txt' % (data_path, dataset_name)\n",
    "embeddings_path = lambda dataset_name: '%s%s_embeddings.npz' % (data_path, dataset_name)\n",
    "\n",
    "datasets = ['lfw', 'cf']\n",
    "\n",
    "data_dfs = []\n",
    "for name in datasets:\n",
    "    data_df = pd.DataFrame(np.load(embeddings_path(name))['arr_0'])\n",
    "    data_df['id'] = retrive_ids(names_path(name))\n",
    "    data_dfs.append(data_df)\n",
    "    \n",
    "test_data_df = pd.concat(data_dfs).sample(frac=1).reset_index(drop=True)\n",
    "X = test_data_df.drop(columns='id').values\n",
    "# X = test_data_df.drop(columns='id').apply(lambda row : (row / np.linalg.norm(row)), axis = 1).values\n",
    "\n",
    "print('Dataset contains %s images of %s different people' % (len(test_data_df), len(test_data_df['id'].value_counts().keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accepted-frank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Generating Log: len(df)=1781, log_length=500...Done.)\n",
      "Log of length 500 with 500 unique faces\n",
      "eps: 9.800000, people: 500 clusters: 491 error: 1.800000\n",
      "\n",
      "(Generating Log: len(df)=1686, log_length=1000...Done.)\n",
      "Log of length 1000 with 500 unique faces\n",
      "eps: 9.800000, people: 500 clusters: 472 error: 5.600000\n",
      "\n",
      "(Generating Log: len(df)=1705, log_length=2500...Done.)\n",
      "Log of length 2500 with 500 unique faces\n",
      "eps: 9.800000, people: 500 clusters: 444 error: 11.200000\n",
      "\n",
      "(Generating Log: len(df)=1682, log_length=4000...Done.)\n",
      "Log of length 4000 with 500 unique faces\n",
      "eps: 9.800000, people: 500 clusters: 469 error: 6.200000\n",
      "\n",
      "(Generating Log: len(df)=1779, log_length=5000...Done.)\n",
      "Log of length 5000 with 500 unique faces\n",
      "eps: 9.800000, people: 500 clusters: 473 error: 5.400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fix n_people, vary log_length\n",
    "log_lengths = [500, 1000, 2500, 4000, 5000]\n",
    "n_people = 500\n",
    "epsilon = 9.8\n",
    "\n",
    "for log_length in log_lengths:\n",
    "    log = generate_log(test_data_df, log_length, n_people).sample(frac=1).reset_index(drop=True)\n",
    "    X = log.drop(columns='id').values\n",
    "    print('Log of length %d with %d unique faces' % (len(log), len(log['id'].value_counts().keys())))\n",
    "    \n",
    "    db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "    labels = pd.Series(db.labels_)\n",
    "\n",
    "    n_people = len(log['id'].value_counts().keys())\n",
    "    n_clusters = len(list(labels.value_counts().values))\n",
    "\n",
    "    est_error = (abs(n_clusters - n_people) / n_people) * 100\n",
    "    print('eps: %f, people: %d clusters: %d error: %f\\n' % (epsilon, n_people, n_clusters, est_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "joined-scoop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Generating Log: len(df)=18380, log_length=5000...Done.)\n",
      "Log of length 5000 with 5000 unique faces\n",
      "eps: 9.800000, people: 5000 clusters: 4353 error: 12.940000\n",
      "\n",
      "(Generating Log: len(df)=18786, log_length=10000...Done.)\n",
      "Log of length 10000 with 5000 unique faces\n",
      "eps: 9.800000, people: 5000 clusters: 4130 error: 17.400000\n",
      "\n",
      "(Generating Log: len(df)=18523, log_length=25000...Done.)\n",
      "Log of length 25000 with 5000 unique faces\n",
      "eps: 9.800000, people: 5000 clusters: 3783 error: 24.340000\n",
      "\n",
      "(Generating Log: len(df)=17673, log_length=40000...Done.)\n",
      "Log of length 40000 with 5000 unique faces\n",
      "eps: 9.800000, people: 5000 clusters: 3764 error: 24.720000\n",
      "\n",
      "(Generating Log: len(df)=18283, log_length=50000...Done.)\n",
      "Log of length 50000 with 5000 unique faces\n",
      "eps: 9.800000, people: 5000 clusters: 3817 error: 23.660000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fix n_people, vary log_length\n",
    "log_lengths = [5000, 10000, 25000, 40000, 50000]\n",
    "n_people = 5000\n",
    "epsilon = 9.8\n",
    "\n",
    "for log_length in log_lengths:\n",
    "    log = generate_log(test_data_df, log_length, n_people).sample(frac=1).reset_index(drop=True)\n",
    "    X = log.drop(columns='id').values\n",
    "    print('Log of length %d with %d unique faces' % (len(log), len(log['id'].value_counts().keys())))\n",
    "    \n",
    "    db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "    labels = pd.Series(db.labels_)\n",
    "\n",
    "    n_people = len(log['id'].value_counts().keys())\n",
    "    n_clusters = len(list(labels.value_counts().values))\n",
    "\n",
    "    est_error = (abs(n_clusters - n_people) / n_people) * 100\n",
    "    print('eps: %f, people: %d clusters: %d error: %f\\n' % (epsilon, n_people, n_clusters, est_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
