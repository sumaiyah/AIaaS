{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "closing-cuisine",
   "metadata": {},
   "source": [
    "# Test Chinese Whispers Clustering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "responsible-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ipynb.fs.full.GenerateLogs import generate_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "corporate-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(datasets):\n",
    "    # Load Datasets\n",
    "    data_path = '../data/'\n",
    "\n",
    "    names_path = lambda dataset_name: '%s%s-names.txt' % (data_path, dataset_name)\n",
    "    embeddings_path = lambda dataset_name: '%s%s_embeddings.npz' % (data_path, dataset_name)\n",
    "\n",
    "    # Return ids of images in each dataset as a list\n",
    "    def retrive_ids(filepath):\n",
    "        with open(filepath, 'r') as file:\n",
    "            ids = file.read().split()\n",
    "        return ids\n",
    "\n",
    "    data_dfs = []\n",
    "    for name in datasets:\n",
    "        data_df = pd.DataFrame(np.load(embeddings_path(name))['arr_0'])\n",
    "        data_df['id'] = retrive_ids(names_path(name))\n",
    "\n",
    "        data_dfs.append(data_df)\n",
    "\n",
    "    all_data_df = pd.concat(data_dfs)\n",
    "    all_data_df = all_data_df.sample(frac=1).reset_index(drop=True)\n",
    "    print('Dataset contains %s images of %s different people' % (len(all_data_df), len(all_data_df['id'].value_counts().keys())))\n",
    "    \n",
    "    return all_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "informal-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Face Cluster \"\"\"\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def face_distance(face_encodings, face_to_compare):\n",
    "    \"\"\"\n",
    "    Given a list of face encodings, compare them to a known face encoding and get a euclidean distance\n",
    "    for each comparison face. The distance tells you how similar the faces are.\n",
    "    :param faces: List of face encodings to compare\n",
    "    :param face_to_compare: A face encoding to compare against\n",
    "    :return: A numpy ndarray with the distance for each face in the same order as the 'faces' array\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    if len(face_encodings) == 0:\n",
    "        return np.empty((0))\n",
    "\n",
    "    #return 1/np.linalg.norm(face_encodings - face_to_compare, axis=1)\n",
    "    face_to_compare = np.array(face_to_compare)\n",
    "    return np.sum(face_encodings*face_to_compare,axis=1)\n",
    "\n",
    "def get_encoding_graph(encoding_list, threshold=0.75):\n",
    "    \"\"\" Chinese Whispers Algorithm\n",
    "    Modified from Alex Loveless' implementation,\n",
    "    http://alexloveless.co.uk/data/chinese-whispers-graph-clustering-in-python/\n",
    "    Inputs:\n",
    "        encoding_list: a list of facial encodings from face_recognition\n",
    "        threshold: facial match threshold,default 0.6\n",
    "        iterations: since chinese whispers is an iterative algorithm, number of times to iterate\n",
    "    Outputs:\n",
    "        sorted_clusters: a list of clusters, a cluster being a list of imagepaths,\n",
    "            sorted by largest cluster to smallest\n",
    "    \"\"\"\n",
    "\n",
    "    #from face_recognition.api import _face_distance\n",
    "    from random import shuffle\n",
    "    import networkx as nx\n",
    "    # Create graph\n",
    "    nodes = []\n",
    "    edges = []\n",
    "\n",
    "    image_paths, encodings = zip(*encoding_list)\n",
    "\n",
    "    if len(encodings) <= 1:\n",
    "        print (\"No enough encodings to cluster!\")\n",
    "        return []\n",
    "\n",
    "    for idx, face_encoding_to_check in enumerate(encodings):\n",
    "        # Adding node of facial encoding\n",
    "        node_id = idx+1\n",
    "\n",
    "        # Initialize 'cluster' to unique value (cluster of itself)\n",
    "        node = (node_id, {'cluster': image_paths[idx], 'path': image_paths[idx]})\n",
    "        nodes.append(node)\n",
    "\n",
    "        # Facial encodings to compare\n",
    "        if (idx+1) >= len(encodings):\n",
    "            # Node is last element, don't create edge\n",
    "            break\n",
    "\n",
    "        compare_encodings = encodings[idx+1:]\n",
    "        distances = face_distance(compare_encodings, face_encoding_to_check)\n",
    "        encoding_edges = []\n",
    "        for i, distance in enumerate(distances):\n",
    "            if distance > threshold:\n",
    "                # Add edge if facial match\n",
    "                edge_id = idx+i+2\n",
    "                encoding_edges.append((node_id, edge_id, {'weight': distance}))\n",
    "\n",
    "        edges = edges + encoding_edges\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ranging-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from chinese_whispers import chinese_whispers, aggregate_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "suburban-irrigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 40995 images of 2000 different people\n"
     ]
    }
   ],
   "source": [
    "data_df = get_data(['celeb_a_1', 'celeb_a_2'])\n",
    "\n",
    "data_df['randNumCol'] = np.random.randint(100000, 999999, data_df.shape[0]).astype(str)\n",
    "data_df['id'] = data_df['id'] + data_df['randNumCol']\n",
    "data_df = data_df.drop(columns='randNumCol')\n",
    "d = data_df.set_index('id').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "anonymous-handling",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-c6c6d3ef8525>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_encoding_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mchinese_whispers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweighting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'top'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-766b6ae4ca72>\u001b[0m in \u001b[0;36mget_encoding_graph\u001b[1;34m(encoding_list, threshold)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mcompare_encodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencodings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompare_encodings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_encoding_to_check\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mencoding_edges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-766b6ae4ca72>\u001b[0m in \u001b[0;36mface_distance\u001b[1;34m(face_encodings, face_to_compare)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#return 1/np.linalg.norm(face_encodings - face_to_compare, axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mface_to_compare\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_to_compare\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mface_to_compare\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_encoding_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "G = get_encoding_graph(d.items(), threshold=90)\n",
    "chinese_whispers(G, weighting='top', iterations=20)\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f\"chinese whispers took {end - start:0.4f} seconds\")\n",
    "\n",
    "print(len(aggregate_clusters(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tracemalloc\n",
    "\n",
    "tracemalloc.start()\n",
    "my_complex_analysis_method()\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB\")\n",
    "tracemalloc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
