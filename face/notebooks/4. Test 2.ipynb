{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "formal-array",
   "metadata": {},
   "source": [
    "# Stalker detection\n",
    "Given a dataset where specifc percentages of the data are one specific individual, can the algorithm correctly pick it out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "equal-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ipynb.fs.full.GenerateLogs import get_encoding_graph, generate_biased_log, get_data, do_chinese_whispers, estimation_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "romance-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform DBScan\n",
    "def do_DBScan(eps, log):\n",
    "    X = log.drop(columns='id').values\n",
    "    epsilon = 9.8\n",
    "\n",
    "    db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "    labels = pd.Series(db.labels_)\n",
    "\n",
    "    n_people = len(log['id'].value_counts().keys())\n",
    "    n_clusters = len(list(labels.value_counts().values))\n",
    "\n",
    "    est_error = (abs(n_clusters - n_people) / n_people) * 100\n",
    "    print('eps: %f, people: %d clusters: %d error: %f' % (epsilon, n_people, n_clusters, est_error))\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-actress",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df = get_data(['lfw', 'cf'])\n",
    "epsilon = 9.8\n",
    "threshold = 71\n",
    "\n",
    "for length in [100, 1000, 2500, 5000, 10000]:\n",
    "    log = generate_biased_log(data_df, log_length=length, proportion=0.1)\n",
    "    n_people = len(log['id'].value_counts().keys())\n",
    "\n",
    "    # DBScan\n",
    "    X = log.drop(columns='id').values\n",
    "    db_start = time.perf_counter()\n",
    "    db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "    db_end = time.perf_counter()\n",
    "    labels = pd.Series(db.labels_)\n",
    "    db_n_clusters = len(list(labels.value_counts().values))\n",
    "    \n",
    "    # Chinese Whispers\n",
    "    log['randID'] = np.random.randint(100000, 999999, log.shape[0]).astype(str)\n",
    "    log['randID'] = log['id'] + log['randID']\n",
    "    d = log.drop(columns='id').set_index('randID').T.to_dict('list')\n",
    "    G = get_encoding_graph(d.items(), threshold=threshold)\n",
    "    # Do Chinese Whispers - Timed\n",
    "    cw_start = time.perf_counter()\n",
    "    cw_clusters = do_chinese_whispers(G)\n",
    "    cw_end = time.perf_counter()\n",
    "    cw_n_clusters = len(cw_clusters.keys())\n",
    " \n",
    "    print('true: ', log['id'].value_counts().values[:10].tolist())\n",
    "    print('db:   ', labels.value_counts().values[:10].tolist())\n",
    "    print('cw:   ', [len(cw_clusters[k]) for k in (sorted(cw_clusters, key=lambda k: len(cw_clusters[k]), reverse=True)[:10])])\n",
    "    \n",
    "    print(f\"DBscan took {db_end - db_start:0.4f} seconds\")\n",
    "    print(f\"CW     took {cw_end - cw_start:0.4f} seconds\")\n",
    "    print('------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log of length 100 with 87 unique people and 10 images of one person\n",
    "# true:  [10, 2, 2, 2, 2, 1, 1, 1, 1, 1]\n",
    "# db:    [10, 3, 2, 2, 2, 1, 1, 1, 1, 1]\n",
    "# cw:    [10, 2, 2, 2, 2, 2, 1, 1, 1, 1]\n",
    "# DBscan took 0.0031 seconds\n",
    "# CW     took 0.0010 seconds\n",
    "# ------------------------------------------------\n",
    "# Log of length 1000 with 711 unique people and 102 images of one person\n",
    "# true:  [102, 15, 5, 4, 4, 4, 4, 4, 3, 3]\n",
    "# db:    [205, 15, 5, 4, 4, 4, 4, 4, 3, 3]\n",
    "# cw:    [104, 16, 10, 8, 6, 5, 5, 5, 5, 4]\n",
    "# DBscan took 0.0279 seconds\n",
    "# CW     took 0.1246 seconds\n",
    "# ------------------------------------------------\n",
    "# Log of length 2500 with 1413 unique people and 252 images of one person\n",
    "# true:  [252, 52, 22, 19, 14, 13, 10, 10, 9, 9]\n",
    "# db:    [667, 65, 22, 18, 11, 11, 9, 9, 8, 7]\n",
    "# cw:    [276, 67, 28, 19, 19, 19, 18, 17, 16, 15]\n",
    "# DBscan took 0.1147 seconds\n",
    "# CW     took 0.7799 seconds\n",
    "# ------------------------------------------------\n",
    "# Log of length 5000 with 2281 unique people and 505 images of one person\n",
    "# true:  [505, 92, 47, 28, 21, 17, 16, 13, 12, 12]\n",
    "# db:    [1597, 94, 47, 28, 21, 19, 18, 13, 12, 11]\n",
    "# cw:    [522, 136, 58, 57, 57, 37, 36, 34, 27, 26]\n",
    "# DBscan took 0.4573 seconds\n",
    "# CW     took 4.3620 seconds\n",
    "# ------------------------------------------------\n",
    "# Log of length 10000 with 3340 unique people and 1053 images of one person\n",
    "# true:  [1053, 217, 86, 34, 31, 28, 27, 26, 26, 25]\n",
    "# db:    [4563, 46, 36, 31, 24, 22, 21, 20, 20, 19]\n",
    "# cw:    [1194, 294, 108, 87, 83, 74, 68, 64, 59, 57]\n",
    "# DBscan took 1.8957 seconds\n",
    "# CW     took 30.4682 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-ranking",
   "metadata": {},
   "source": [
    "## T-SNE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = generate_biased_log(data_df, log_length=600, proportion=0.10)\n",
    "\n",
    "tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "new_values = tsne_model.fit_transform(log.drop(columns='id').values)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for value in new_values:\n",
    "    x.append(value[0])\n",
    "    y.append(value[1])\n",
    "\n",
    "# unique colour for each person\n",
    "df = pd.DataFrame({'x':x, 'y':y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,6))\n",
    "sns.scatterplot(\n",
    "    x=\"x\", y=\"y\",\n",
    "    hue=log['id'].reset_index(drop=True),\n",
    "    palette=sns.color_palette(\"colorblind\", log['id'].nunique()),\n",
    "    data=df,\n",
    "    legend=False,\n",
    "    alpha=0.9,\n",
    "    s=60\n",
    ")\n",
    "\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.savefig('figs/test2-tsne-600.png', bbox_inches='tight', dpi=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
