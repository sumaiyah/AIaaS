{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "threatened-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ipynb.fs.full.GenerateLogs import generate_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "divided-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(datasets):\n",
    "    # Load Datasets\n",
    "    data_path = '../data/'\n",
    "\n",
    "    names_path = lambda dataset_name: '%s%s-names.txt' % (data_path, dataset_name)\n",
    "    embeddings_path = lambda dataset_name: '%s%s_embeddings.npz' % (data_path, dataset_name)\n",
    "\n",
    "    # Return ids of images in each dataset as a list\n",
    "    def retrive_ids(filepath):\n",
    "        with open(filepath, 'r') as file:\n",
    "            ids = file.read().split()\n",
    "        return ids\n",
    "\n",
    "    data_dfs = []\n",
    "    for name in datasets:\n",
    "        data_df = pd.DataFrame(np.load(embeddings_path(name))['arr_0'])\n",
    "        data_df['id'] = retrive_ids(names_path(name))\n",
    "\n",
    "        data_dfs.append(data_df)\n",
    "\n",
    "    all_data_df = pd.concat(data_dfs)\n",
    "    all_data_df = all_data_df.sample(frac=1).reset_index(drop=True)\n",
    "    print('Dataset contains %s images of %s different people\\n' % (len(all_data_df), len(all_data_df['id'].value_counts().keys())))\n",
    "    \n",
    "    return all_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bulgarian-opinion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 24517 images of 6743 different people\n",
      "\n",
      "(Generating Log: len(df)=372, log_length=1000...Done.)\n",
      "Log of length 1000 with 100 unique faces\n"
     ]
    }
   ],
   "source": [
    "data_df = get_data(['lfw', 'cf'])\n",
    "log_length, n_people = 1000, 100\n",
    "\n",
    "log = generate_log(data_df, log_length, n_people).sample(frac=1).reset_index(drop=True)\n",
    "X = log.drop(columns='id').values\n",
    "print('Log of length %d with %d unique faces' % (len(log), len(log['id'].value_counts().keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spectacular-office",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps: 9.800000, people: 100 clusters: 99 error: 1.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon = 9.8\n",
    "\n",
    "db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "labels = pd.Series(db.labels_)\n",
    "\n",
    "n_people = len(log['id'].value_counts().keys())\n",
    "n_clusters = len(list(labels.value_counts().values))\n",
    "\n",
    "est_error = (abs(n_clusters - n_people) / n_people) * 100\n",
    "print('eps: %f, people: %d clusters: %d error: %f\\n' % (epsilon, n_people, n_clusters, est_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acknowledged-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(log['id'])\n",
    "results['cluster'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "single-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = []\n",
    "for label, images in results.groupby('cluster'):\n",
    "    person_counts = pd.Series(images.values[:,0]).value_counts()\n",
    "    \n",
    "    person_proportion = person_counts / person_counts.values.sum()\n",
    "    \n",
    "    people.append(person_proportion.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sensitive-smoke",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "people_counter = Counter(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "understood-conference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given 1000 pictures of 100 unique people the clustering algorithm found 99 clusters but of those only 94 are of unique people\n"
     ]
    }
   ],
   "source": [
    "print('Given %d pictures of %d unique people the clustering algorithm found %d clusters but of those only %d are of unique people' % (log_length, n_people, n_clusters, len(people_counter.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "decreased-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X clusters were 100% correct, X clusters were mixed? X people are missed out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "For each cluster \n",
    "- Assign a label to the cluster as the most popular image id in that cluster\n",
    "- Save label, confidence in df \n",
    "- If tie?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
