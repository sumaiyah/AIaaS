{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tough-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ipynb.fs.full.GenerateLogs import generate_log, get_data, get_encoding_graph, do_chinese_whispers, estimation_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comprehensive-notice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 24517 images of 6743 different people \n",
      "\n",
      "This is round 1\n",
      "Log of length 1000 with 50 unique faces\n",
      "DBScan: people: 50 clusters: 51 error: 2.000000\n",
      "CW:     people: 50 clusters: 53 error: 6.000000\n",
      "DBscan took 0.025 seconds\n",
      "CW     took 0.148 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 100 unique faces\n",
      "DBScan: people: 100 clusters: 104 error: 4.000000\n",
      "CW:     people: 100 clusters: 120 error: 20.000000\n",
      "DBscan took 0.026 seconds\n",
      "CW     took 0.086 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 250 unique faces\n",
      "DBScan: people: 250 clusters: 257 error: 2.800000\n",
      "CW:     people: 250 clusters: 265 error: 6.000000\n",
      "DBscan took 0.025 seconds\n",
      "CW     took 0.140 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 400 unique faces\n",
      "DBScan: people: 400 clusters: 377 error: 5.750000\n",
      "CW:     people: 400 clusters: 365 error: 8.750000\n",
      "DBscan took 0.026 seconds\n",
      "CW     took 0.110 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 467 error: 6.600000\n",
      "CW:     people: 500 clusters: 429 error: 14.200000\n",
      "DBscan took 0.024 seconds\n",
      "CW     took 0.234 seconds\n",
      "----------------------------------------------\n",
      "This is round 2\n",
      "Log of length 1000 with 50 unique faces\n",
      "DBScan: people: 50 clusters: 58 error: 16.000000\n",
      "CW:     people: 50 clusters: 56 error: 12.000000\n",
      "DBscan took 0.022 seconds\n",
      "CW     took 0.170 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 100 unique faces\n",
      "DBScan: people: 100 clusters: 109 error: 9.000000\n",
      "CW:     people: 100 clusters: 104 error: 4.000000\n",
      "DBscan took 0.022 seconds\n",
      "CW     took 0.106 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 250 unique faces\n",
      "DBScan: people: 250 clusters: 251 error: 0.400000\n",
      "CW:     people: 250 clusters: 260 error: 4.000000\n",
      "DBscan took 0.024 seconds\n",
      "CW     took 0.124 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 400 unique faces\n",
      "DBScan: people: 400 clusters: 379 error: 5.250000\n",
      "CW:     people: 400 clusters: 378 error: 5.500000\n",
      "DBscan took 0.025 seconds\n",
      "CW     took 0.414 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 466 error: 6.800000\n",
      "CW:     people: 500 clusters: 451 error: 9.800000\n",
      "DBscan took 0.023 seconds\n",
      "CW     took 0.214 seconds\n",
      "----------------------------------------------\n",
      "This is round 3\n",
      "Log of length 1000 with 50 unique faces\n",
      "DBScan: people: 50 clusters: 47 error: 6.000000\n",
      "CW:     people: 50 clusters: 64 error: 28.000000\n",
      "DBscan took 0.029 seconds\n",
      "CW     took 0.164 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 100 unique faces\n",
      "DBScan: people: 100 clusters: 100 error: 0.000000\n",
      "CW:     people: 100 clusters: 120 error: 20.000000\n",
      "DBscan took 0.023 seconds\n",
      "CW     took 0.113 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 250 unique faces\n",
      "DBScan: people: 250 clusters: 247 error: 1.200000\n",
      "CW:     people: 250 clusters: 265 error: 6.000000\n",
      "DBscan took 0.023 seconds\n",
      "CW     took 0.166 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 400 unique faces\n",
      "DBScan: people: 400 clusters: 378 error: 5.500000\n",
      "CW:     people: 400 clusters: 367 error: 8.250000\n",
      "DBscan took 0.023 seconds\n",
      "CW     took 0.110 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 473 error: 5.400000\n",
      "CW:     people: 500 clusters: 439 error: 12.200000\n",
      "DBscan took 0.023 seconds\n",
      "CW     took 0.085 seconds\n",
      "----------------------------------------------\n",
      "This is round 4\n",
      "Log of length 1000 with 50 unique faces\n",
      "DBScan: people: 50 clusters: 51 error: 2.000000\n",
      "CW:     people: 50 clusters: 53 error: 6.000000\n",
      "DBscan took 0.024 seconds\n",
      "CW     took 0.137 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 100 unique faces\n",
      "DBScan: people: 100 clusters: 107 error: 7.000000\n",
      "CW:     people: 100 clusters: 116 error: 16.000000\n",
      "DBscan took 0.021 seconds\n",
      "CW     took 0.145 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 250 unique faces\n",
      "DBScan: people: 250 clusters: 252 error: 0.800000\n",
      "CW:     people: 250 clusters: 263 error: 5.200000\n",
      "DBscan took 0.027 seconds\n",
      "CW     took 0.089 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 400 unique faces\n",
      "DBScan: people: 400 clusters: 387 error: 3.250000\n",
      "CW:     people: 400 clusters: 388 error: 3.000000\n",
      "DBscan took 0.024 seconds\n",
      "CW     took 0.136 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 466 error: 6.800000\n",
      "CW:     people: 500 clusters: 464 error: 7.200000\n",
      "DBscan took 0.025 seconds\n",
      "CW     took 0.613 seconds\n",
      "----------------------------------------------\n",
      "This is round 5\n",
      "Log of length 1000 with 50 unique faces\n",
      "DBScan: people: 50 clusters: 55 error: 10.000000\n",
      "CW:     people: 50 clusters: 51 error: 2.000000\n",
      "DBscan took 0.026 seconds\n",
      "CW     took 0.217 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 100 unique faces\n",
      "DBScan: people: 100 clusters: 100 error: 0.000000\n",
      "CW:     people: 100 clusters: 105 error: 5.000000\n",
      "DBscan took 0.024 seconds\n",
      "CW     took 0.145 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 250 unique faces\n",
      "DBScan: people: 250 clusters: 243 error: 2.800000\n",
      "CW:     people: 250 clusters: 260 error: 4.000000\n",
      "DBscan took 0.024 seconds\n",
      "CW     took 0.121 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 400 unique faces\n",
      "DBScan: people: 400 clusters: 385 error: 3.750000\n",
      "CW:     people: 400 clusters: 357 error: 10.750000\n",
      "DBscan took 0.024 seconds\n",
      "CW     took 0.132 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 462 error: 7.600000\n",
      "CW:     people: 500 clusters: 450 error: 10.000000\n",
      "DBscan took 0.023 seconds\n",
      "CW     took 0.082 seconds\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Fix log_length, vary n_people\n",
    "log_length = 1000\n",
    "n_peoples = [50, 100, 250, 400, 500]\n",
    "\n",
    "result_file_name = 'log_%d_n_vary.txt' % log_length\n",
    "\n",
    "epsilon = 9.8\n",
    "threshold = 72\n",
    "\n",
    "# Get data\n",
    "data_df = get_data(['lfw', 'cf'])\n",
    "\n",
    "for i in range(5):\n",
    "    print('This is round %d' % (i+1))\n",
    "    for n_people in n_peoples:\n",
    "        # Generate log\n",
    "        log = generate_log(data_df, log_length=log_length, n_faces=n_people, exact=True).sample(frac=1).reset_index(drop=True)\n",
    "        n_people = len(log['id'].value_counts().keys())\n",
    "        print('Log of length %d with %d unique faces' % (len(log), n_people))\n",
    "\n",
    "        # DBScan\n",
    "        X = log.drop(columns='id').values\n",
    "        # Do DBScan - Timed\n",
    "        db_start = time.perf_counter()\n",
    "        db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "        db_end = time.perf_counter()\n",
    "        labels = pd.Series(db.labels_)\n",
    "        db_n_clusters = len(list(labels.value_counts().values))\n",
    "\n",
    "        # Chinese Whispers\n",
    "        log['randID'] = np.random.randint(100000, 999999, log.shape[0]).astype(str)\n",
    "        log['randID'] = log['id'] + log['randID']\n",
    "        d = log.drop(columns='id').set_index('randID').T.to_dict('list')\n",
    "        G = get_encoding_graph(d.items(), threshold=threshold)\n",
    "        # Do Chinese Whispers - Timed \n",
    "        cw_start = time.perf_counter()\n",
    "        cw_clusters = do_chinese_whispers(G)\n",
    "        cw_end = time.perf_counter()\n",
    "        cw_n_clusters = len(cw_clusters.keys())\n",
    "\n",
    "        # Save results to text file\n",
    "        with open(result_file_name, 'a') as file:\n",
    "            file.write(('alg:db log_length:%d n_people:%d n_clusters:%d time:' % (log_length, n_people, db_n_clusters) + f'{db_end - db_start:0.3f}' + '\\n'))\n",
    "            file.write(('alg:cw log_length:%d n_people:%d n_clusters:%d time:' % (log_length, n_people, cw_n_clusters) + f'{cw_end - cw_start:0.3f}' + '\\n'))\n",
    "\n",
    "        # Print results\n",
    "        db_est_err = estimation_error(n_clusters=db_n_clusters, n_people=n_people)\n",
    "        cw_est_err = estimation_error(n_clusters=cw_n_clusters, n_people=n_people)\n",
    "\n",
    "        print('DBScan: people: %d clusters: %d error: %f' % (n_people, db_n_clusters, db_est_err))\n",
    "        print('CW:     people: %d clusters: %d error: %f' % (n_people, cw_n_clusters, cw_est_err))\n",
    "\n",
    "        print(f\"DBscan took {db_end - db_start:0.3f} seconds\")\n",
    "        print(f\"CW     took {cw_end - cw_start:0.3f} seconds\")\n",
    "\n",
    "        print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-stranger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 24517 images of 6743 different people \n",
      "\n",
      "This is round 1\n",
      "Log of length 10000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 488 error: 2.400000\n",
      "CW:     people: 500 clusters: 604 error: 20.800000\n",
      "DBscan took 4.0398 seconds\n",
      "CW     took 2.7920 seconds\n",
      "----------------------------------------------\n",
      "Log of length 10000 with 1000 unique faces\n"
     ]
    }
   ],
   "source": [
    "# Fix log_length, vary n_people\n",
    "log_length = 10000\n",
    "n_peoples = [500, 1000, 2500, 4000, 5000]\n",
    "\n",
    "result_file_name = 'log_%d_n_vary.txt' % log_length\n",
    "\n",
    "epsilon = 9.8\n",
    "threshold = 72\n",
    "\n",
    "# Get data\n",
    "data_df = get_data(['lfw', 'cf'])\n",
    "\n",
    "for i in range(1):\n",
    "    print('This is round %d' % (i+1))\n",
    "    for n_people in n_peoples:\n",
    "        # Generate log\n",
    "        log = generate_log(data_df, log_length=log_length, n_faces=n_people, exact=True).sample(frac=1).reset_index(drop=True)\n",
    "        n_people = len(log['id'].value_counts().keys())\n",
    "        print('Log of length %d with %d unique faces' % (len(log), n_people))\n",
    "\n",
    "        # DBScan\n",
    "        X = log.drop(columns='id').values\n",
    "        # Do DBScan - Timed\n",
    "        db_start = time.perf_counter()\n",
    "        db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "        db_end = time.perf_counter()\n",
    "        labels = pd.Series(db.labels_)\n",
    "        db_n_clusters = len(list(labels.value_counts().values))\n",
    "\n",
    "        # Chinese Whispers\n",
    "        log['randID'] = np.random.randint(100000, 999999, log.shape[0]).astype(str)\n",
    "        log['randID'] = log['id'] + log['randID']\n",
    "        d = log.drop(columns='id').set_index('randID').T.to_dict('list')\n",
    "        G = get_encoding_graph(d.items(), threshold=threshold)\n",
    "        # Do Chinese Whispers - Timed\n",
    "        cw_start = time.perf_counter()\n",
    "        cw_clusters = do_chinese_whispers(G)\n",
    "        cw_end = time.perf_counter()\n",
    "        cw_n_clusters = len(cw_clusters.keys())\n",
    "\n",
    "        # Save results to text file\n",
    "        with open(result_file_name, 'a') as file:\n",
    "            file.write(('alg:db log_length:%d n_people:%d n_clusters:%d time:' % (log_length, n_people, db_n_clusters) + f'{db_end - db_start:0.3f}' + '\\n'))\n",
    "            file.write(('alg:cw log_length:%d n_people:%d n_clusters:%d time:' % (log_length, n_people, cw_n_clusters) + f'{cw_end - cw_start:0.3f}' + '\\n'))\n",
    "\n",
    "        # Print results\n",
    "        db_est_err = estimation_error(n_clusters=db_n_clusters, n_people=n_people)\n",
    "        cw_est_err = estimation_error(n_clusters=cw_n_clusters, n_people=n_people)\n",
    "\n",
    "        print('DBScan: people: %d clusters: %d error: %f' % (n_people, db_n_clusters, db_est_err))\n",
    "        print('CW:     people: %d clusters: %d error: %f' % (n_people, cw_n_clusters, cw_est_err))\n",
    "\n",
    "        print(f\"DBscan took {db_end - db_start:0.4f} seconds\")\n",
    "        print(f\"CW     took {cw_end - cw_start:0.4f} seconds\") \n",
    "        print('----------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
