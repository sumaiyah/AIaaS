{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authentic-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ipynb.fs.full.GenerateLogs import generate_log, get_data, do_chinese_whispers, estimation_error, get_encoding_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fallen-firewall",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 24517 images of 6743 different people \n",
      "\n",
      "This is round 1\n",
      "Log of length 500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 471 error: 5.800000\n",
      "DBscan took 0.0107 seconds\n",
      "CW:     people: 500 clusters: 450 error: 10.000000\n",
      "CW     took 0.0071 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 485 error: 3.000000\n",
      "DBscan took 0.0263 seconds\n",
      "CW:     people: 500 clusters: 447 error: 10.600000\n",
      "CW     took 0.1404 seconds\n",
      "----------------------------------------------\n",
      "Log of length 2500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 450 error: 10.000000\n",
      "DBscan took 0.2055 seconds\n",
      "CW:     people: 500 clusters: 474 error: 5.200000\n",
      "CW     took 0.9807 seconds\n",
      "----------------------------------------------\n",
      "Log of length 4000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 475 error: 5.000000\n",
      "DBscan took 0.3061 seconds\n",
      "CW:     people: 500 clusters: 563 error: 12.600000\n",
      "CW     took 0.8629 seconds\n",
      "----------------------------------------------\n",
      "Log of length 5000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 465 error: 7.000000\n",
      "DBscan took 0.4960 seconds\n",
      "CW:     people: 500 clusters: 538 error: 7.600000\n",
      "CW     took 1.1554 seconds\n",
      "----------------------------------------------\n",
      "This is round 2\n",
      "Log of length 500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 475 error: 5.000000\n",
      "DBscan took 0.0094 seconds\n",
      "CW:     people: 500 clusters: 441 error: 11.800000\n",
      "CW     took 0.0081 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 494 error: 1.200000\n",
      "DBscan took 0.0280 seconds\n",
      "CW:     people: 500 clusters: 439 error: 12.200000\n",
      "CW     took 0.1782 seconds\n",
      "----------------------------------------------\n",
      "Log of length 2500 with 500 unique faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bfb70f0b49e6>:33: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  d = log.drop(columns='id').set_index('randID').T.to_dict('list')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBScan: people: 500 clusters: 468 error: 6.400000\n",
      "DBscan took 0.1551 seconds\n",
      "CW:     people: 500 clusters: 538 error: 7.600000\n",
      "CW     took 0.5531 seconds\n",
      "----------------------------------------------\n",
      "Log of length 4000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 473 error: 5.400000\n",
      "DBscan took 0.3238 seconds\n",
      "CW:     people: 500 clusters: 543 error: 8.600000\n",
      "CW     took 0.8557 seconds\n",
      "----------------------------------------------\n",
      "Log of length 5000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 487 error: 2.600000\n",
      "DBscan took 0.6021 seconds\n",
      "CW:     people: 500 clusters: 558 error: 11.600000\n",
      "CW     took 5.0587 seconds\n",
      "----------------------------------------------\n",
      "This is round 3\n",
      "Log of length 500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 466 error: 6.800000\n",
      "DBscan took 0.0101 seconds\n",
      "CW:     people: 500 clusters: 446 error: 10.800000\n",
      "CW     took 0.0123 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 477 error: 4.600000\n",
      "DBscan took 0.0293 seconds\n",
      "CW:     people: 500 clusters: 440 error: 12.000000\n",
      "CW     took 0.1594 seconds\n",
      "----------------------------------------------\n",
      "Log of length 2500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 459 error: 8.200000\n",
      "DBscan took 0.1518 seconds\n",
      "CW:     people: 500 clusters: 497 error: 0.600000\n",
      "CW     took 0.4120 seconds\n",
      "----------------------------------------------\n",
      "Log of length 4000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 484 error: 3.200000\n",
      "DBscan took 0.3036 seconds\n",
      "CW:     people: 500 clusters: 518 error: 3.600000\n",
      "CW     took 3.5420 seconds\n",
      "----------------------------------------------\n",
      "Log of length 5000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 451 error: 9.800000\n",
      "DBscan took 0.6113 seconds\n",
      "CW:     people: 500 clusters: 562 error: 12.400000\n",
      "CW     took 1.0587 seconds\n",
      "----------------------------------------------\n",
      "This is round 4\n",
      "Log of length 500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 482 error: 3.600000\n",
      "DBscan took 0.0080 seconds\n",
      "CW:     people: 500 clusters: 448 error: 10.400000\n",
      "CW     took 0.0069 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 474 error: 5.200000\n",
      "DBscan took 0.0248 seconds\n",
      "CW:     people: 500 clusters: 434 error: 13.200000\n",
      "CW     took 0.2449 seconds\n",
      "----------------------------------------------\n",
      "Log of length 2500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 471 error: 5.800000\n",
      "DBscan took 0.1327 seconds\n",
      "CW:     people: 500 clusters: 513 error: 2.600000\n",
      "CW     took 0.4528 seconds\n",
      "----------------------------------------------\n",
      "Log of length 4000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 465 error: 7.000000\n",
      "DBscan took 0.3270 seconds\n",
      "CW:     people: 500 clusters: 510 error: 2.000000\n",
      "CW     took 0.6174 seconds\n",
      "----------------------------------------------\n",
      "Log of length 5000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 473 error: 5.400000\n",
      "DBscan took 0.4791 seconds\n",
      "CW:     people: 500 clusters: 572 error: 14.400000\n",
      "CW     took 1.3219 seconds\n",
      "----------------------------------------------\n",
      "This is round 5\n",
      "Log of length 500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 479 error: 4.200000\n",
      "DBscan took 0.0094 seconds\n",
      "CW:     people: 500 clusters: 438 error: 12.400000\n",
      "CW     took 0.0066 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 455 error: 9.000000\n",
      "DBscan took 0.0321 seconds\n",
      "CW:     people: 500 clusters: 440 error: 12.000000\n",
      "CW     took 0.1019 seconds\n",
      "----------------------------------------------\n",
      "Log of length 2500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 479 error: 4.200000\n",
      "DBscan took 0.1356 seconds\n",
      "CW:     people: 500 clusters: 502 error: 0.400000\n",
      "CW     took 0.4420 seconds\n",
      "----------------------------------------------\n",
      "Log of length 4000 with 500 unique faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bfb70f0b49e6>:33: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  d = log.drop(columns='id').set_index('randID').T.to_dict('list')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBScan: people: 500 clusters: 479 error: 4.200000\n",
      "DBscan took 0.3527 seconds\n",
      "CW:     people: 500 clusters: 537 error: 7.400000\n",
      "CW     took 5.8647 seconds\n",
      "----------------------------------------------\n",
      "Log of length 5000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 476 error: 4.800000\n",
      "DBscan took 0.5574 seconds\n",
      "CW:     people: 500 clusters: 564 error: 12.800000\n",
      "CW     took 1.2980 seconds\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Fix log_length, vary n_people\n",
    "log_lengths = [500, 1000, 2500, 4000, 5000]\n",
    "n_peoples = 500\n",
    "\n",
    "result_file_name = 'log_vary_n_%d.txt' % n_peoples\n",
    "\n",
    "\n",
    "epsilon = 9.8\n",
    "threshold = 72\n",
    "\n",
    "# Get data\n",
    "data_df = get_data(['lfw', 'cf'])\n",
    "\n",
    "for i in range(5):\n",
    "    print('This is round %d' % (i+1))\n",
    "    for log_length in log_lengths:\n",
    "        # Generate log\n",
    "        log = generate_log(data_df, log_length=log_length, n_faces=n_peoples, exact=True).sample(frac=1).reset_index(drop=True)\n",
    "        n_people = len(log['id'].value_counts().keys())\n",
    "        print('Log of length %d with %d unique faces' % (len(log), n_people))\n",
    "\n",
    "        # DBScan\n",
    "        X = log.drop(columns='id').values\n",
    "        # Do DBScan - Timed\n",
    "        db_start = time.perf_counter()\n",
    "        db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "        db_end = time.perf_counter()\n",
    "        labels = pd.Series(db.labels_)\n",
    "        db_n_clusters = len(list(labels.value_counts().values))\n",
    "\n",
    "        # Chinese Whispers\n",
    "        log['randID'] = np.random.randint(100000, 999999, log.shape[0]).astype(str)\n",
    "        log['randID'] = log['id'] + log['randID']\n",
    "        d = log.drop(columns='id').set_index('randID').T.to_dict('list')\n",
    "        G = get_encoding_graph(d.items(), threshold=threshold)\n",
    "        # Do Chinese Whispers - Timed\n",
    "        cw_start = time.perf_counter()\n",
    "        cw_clusters = do_chinese_whispers(G)\n",
    "        cw_end = time.perf_counter()\n",
    "        cw_n_clusters = len(cw_clusters.keys())\n",
    "\n",
    "        # Save results to text file\n",
    "        with open(result_file_name, 'a') as file:\n",
    "            file.write(('alg:db log_length:%d n_people:%d n_clusters:%d time:' % (log_length, n_people, db_n_clusters) + f'{db_end - db_start:0.3f}' + '\\n'))\n",
    "            file.write(('alg:cw log_length:%d n_people:%d n_clusters:%d time:' % (log_length, n_people, cw_n_clusters) + f'{cw_end - cw_start:0.3f}' + '\\n'))\n",
    "\n",
    "        # Print results\n",
    "        db_est_err = estimation_error(n_clusters=db_n_clusters, n_people=n_people)\n",
    "        cw_est_err = estimation_error(n_clusters=cw_n_clusters, n_people=n_people)\n",
    "\n",
    "        print('DBScan: people: %d clusters: %d error: %f' % (n_people, db_n_clusters, db_est_err))\n",
    "        print(f\"DBscan took {db_end - db_start:0.4f} seconds\")\n",
    "\n",
    "        print('CW:     people: %d clusters: %d error: %f' % (n_people, cw_n_clusters, cw_est_err))\n",
    "        print(f\"CW     took {cw_end - cw_start:0.4f} seconds\") \n",
    "        print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Cancel this!!!!!!!!!\n",
    "# Fix log_length, vary n_people\n",
    "log_lengths = [5000, 10000, 25000, 40000, 50000]\n",
    "n_peoples = 5000\n",
    "\n",
    "result_file_name = 'log_vary_n_%d.txt' % n_peoples\n",
    "\n",
    "epsilon = 9.8\n",
    "threshold = 72\n",
    "\n",
    "# Get data\n",
    "data_df = get_data(['lfw', 'cf'])\n",
    "\n",
    "for i in range(5):\n",
    "    print('This is round %d' % (i+1))\n",
    "    for log_length in log_lengths:\n",
    "        # Generate log\n",
    "        log = generate_log(data_df, log_length=log_length, n_faces=n_peoples, exact=True).sample(frac=1).reset_index(drop=True)\n",
    "        n_people = len(log['id'].value_counts().keys())\n",
    "        print('Log of length %d with %d unique faces' % (len(log), n_people))\n",
    "\n",
    "        # DBScan\n",
    "        X = log.drop(columns='id').values\n",
    "        # Do DBScan - Timed\n",
    "        db_start = time.perf_counter()\n",
    "        db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "        db_end = time.perf_counter()\n",
    "        labels = pd.Series(db.labels_)\n",
    "        db_n_clusters = len(list(labels.value_counts().values))\n",
    "\n",
    "        # Chinese Whispers\n",
    "        log['randID'] = np.random.randint(100000, 999999, log.shape[0]).astype(str)\n",
    "        log['randID'] = log['id'] + log['randID']\n",
    "        d = log.drop(columns='id').set_index('randID').T.to_dict('list')\n",
    "        # Do Chinese Whispers - Timed\n",
    "        cw_start = time.perf_counter()\n",
    "        cw_clusters = do_chinese_whispers(d, threshold=threshold)\n",
    "        cw_end = time.perf_counter()\n",
    "        cw_n_clusters = len(cw_clusters.keys())\n",
    "\n",
    "        # Save results to text file\n",
    "        with open(result_file_name, 'a') as file:\n",
    "            file.write(('alg:db log_length:%d n_people:%d n_clusters:%d time:' % (log_length, n_people, db_n_clusters) + f'{db_end - db_start:0.3f}' + '\\n'))\n",
    "            file.write(('alg:cw log_length:%d n_people:%d n_clusters:%d time:' % (log_length, n_people, cw_n_clusters) + f'{cw_end - cw_start:0.3f}' + '\\n'))\n",
    "\n",
    "        # Print results\n",
    "        db_est_err = estimation_error(n_clusters=db_n_clusters, n_people=n_people)\n",
    "        cw_est_err = estimation_error(n_clusters=cw_n_clusters, n_people=n_people)\n",
    "\n",
    "        print('DBScan: people: %d clusters: %d error: %f' % (n_people, db_n_clusters, db_est_err))\n",
    "        print(f\"DBscan took {db_end - db_start:0.4f} seconds\")\n",
    "\n",
    "        print('CW:     people: %d clusters: %d error: %f' % (n_people, cw_n_clusters, cw_est_err))\n",
    "        print(f\"CW     took {cw_end - cw_start:0.4f} seconds\") \n",
    "        print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-badge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
