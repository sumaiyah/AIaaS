{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "silver-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ipynb.fs.full.GenerateLogs import generate_log, get_data, do_chinese_whispers, estimation_error, get_encoding_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "humanitarian-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 24517 images of 6743 different people \n",
      "\n",
      "Log of length 500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 476 error: 4.800000\n",
      "DBscan took 0.0077 seconds\n",
      "CW:     people: 500 clusters: 448 error: 10.400000\n",
      "CW     took 0.0069 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 487 error: 2.600000\n",
      "DBscan took 0.0220 seconds\n",
      "CW:     people: 500 clusters: 435 error: 13.000000\n",
      "CW     took 0.1169 seconds\n",
      "----------------------------------------------\n",
      "Log of length 2500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 460 error: 8.000000\n",
      "DBscan took 0.1068 seconds\n",
      "CW:     people: 500 clusters: 512 error: 2.400000\n",
      "CW     took 0.3570 seconds\n",
      "----------------------------------------------\n",
      "Log of length 4000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 460 error: 8.000000\n",
      "DBscan took 0.3293 seconds\n",
      "CW:     people: 500 clusters: 573 error: 14.600000\n",
      "CW     took 1.5387 seconds\n",
      "----------------------------------------------\n",
      "Log of length 5000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 471 error: 5.800000\n",
      "DBscan took 0.4647 seconds\n",
      "CW:     people: 500 clusters: 536 error: 7.200000\n",
      "CW     took 0.7518 seconds\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Fix log_length, vary n_people\n",
    "log_lengths = [500, 1000, 2500, 4000, 5000]\n",
    "n_peoples = 500\n",
    "\n",
    "epsilon = 9.8\n",
    "threshold = 72\n",
    "\n",
    "# Get data\n",
    "data_df = get_data(['lfw', 'cf'])\n",
    "\n",
    "for log_length in log_lengths:\n",
    "    # Generate log\n",
    "    log = generate_log(data_df, log_length=log_length, n_faces=n_peoples, exact=True).sample(frac=1).reset_index(drop=True)\n",
    "    n_people = len(log['id'].value_counts().keys())\n",
    "    print('Log of length %d with %d unique faces' % (len(log), n_people))\n",
    "        \n",
    "    # DBScan\n",
    "    X = log.drop(columns='id').values\n",
    "    # Do DBScan - Timed\n",
    "    db_start = time.perf_counter()\n",
    "    db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "    db_end = time.perf_counter()\n",
    "    labels = pd.Series(db.labels_)\n",
    "    db_n_clusters = len(list(labels.value_counts().values))\n",
    "    \n",
    "    # Chinese Whispers\n",
    "    log['randID'] = np.random.randint(100000, 999999, log.shape[0]).astype(str)\n",
    "    log['randID'] = log['id'] + log['randID']\n",
    "    d = log.drop(columns='id').set_index('randID').T.to_dict('list')\n",
    "    G = get_encoding_graph(d.items(), threshold=threshold)\n",
    "    # Do Chinese Whispers - Timed\n",
    "    cw_start = time.perf_counter()\n",
    "    cw_clusters = do_chinese_whispers(G)\n",
    "    cw_end = time.perf_counter()\n",
    "    cw_n_clusters = len(cw_clusters.keys())\n",
    "\n",
    "    # Print results\n",
    "    db_est_err = estimation_error(n_clusters=db_n_clusters, n_people=n_people)\n",
    "    cw_est_err = estimation_error(n_clusters=cw_n_clusters, n_people=n_people)\n",
    "    \n",
    "    print('DBScan: people: %d clusters: %d error: %f' % (n_people, db_n_clusters, db_est_err))\n",
    "    print(f\"DBscan took {db_end - db_start:0.4f} seconds\")\n",
    "    \n",
    "    print('CW:     people: %d clusters: %d error: %f' % (n_people, cw_n_clusters, cw_est_err))\n",
    "    print(f\"CW     took {cw_end - cw_start:0.4f} seconds\") \n",
    "    print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix log_length, vary n_people\n",
    "log_lengths = [5000, 10000, 25000, 40000, 50000]\n",
    "n_peoples = 5000\n",
    "\n",
    "epsilon = 9.8\n",
    "threshold = 72\n",
    "\n",
    "# Get data\n",
    "data_df = get_data(['lfw', 'cf'])\n",
    "\n",
    "for log_length in log_lengths:\n",
    "    # Generate log\n",
    "    log = generate_log(data_df, log_length=log_length, n_faces=n_peoples, exact=True).sample(frac=1).reset_index(drop=True)\n",
    "    n_people = len(log['id'].value_counts().keys())\n",
    "    print('Log of length %d with %d unique faces' % (len(log), n_people))\n",
    "        \n",
    "    # DBScan\n",
    "    X = log.drop(columns='id').values\n",
    "    # Do DBScan - Timed\n",
    "    db_start = time.perf_counter()\n",
    "    db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "    db_end = time.perf_counter()\n",
    "    labels = pd.Series(db.labels_)\n",
    "    db_n_clusters = len(list(labels.value_counts().values))\n",
    "    \n",
    "    # Chinese Whispers\n",
    "    log['randID'] = np.random.randint(100000, 999999, log.shape[0]).astype(str)\n",
    "    log['randID'] = log['id'] + log['randID']\n",
    "    d = log.drop(columns='id').set_index('randID').T.to_dict('list')\n",
    "    # Do Chinese Whispers - Timed\n",
    "    cw_start = time.perf_counter()\n",
    "    cw_clusters = do_chinese_whispers(d, threshold=threshold)\n",
    "    cw_end = time.perf_counter()\n",
    "    cw_n_clusters = len(cw_clusters.keys())\n",
    "\n",
    "    # Print results\n",
    "    db_est_err = estimation_error(n_clusters=db_n_clusters, n_people=n_people)\n",
    "    cw_est_err = estimation_error(n_clusters=cw_n_clusters, n_people=n_people)\n",
    "    \n",
    "    print('DBScan: people: %d clusters: %d error: %f' % (n_people, db_n_clusters, db_est_err))\n",
    "    print(f\"DBscan took {db_end - db_start:0.4f} seconds\")\n",
    "    \n",
    "    print('CW:     people: %d clusters: %d error: %f' % (n_people, cw_n_clusters, cw_est_err))\n",
    "    print(f\"CW     took {cw_end - cw_start:0.4f} seconds\") \n",
    "    print('----------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
