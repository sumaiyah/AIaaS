{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blank-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ipynb.fs.full.GenerateLogs import generate_log, get_data, do_chinese_whispers, estimation_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "patient-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 24517 images of 6743 different people \n",
      "\n",
      "Log of length 500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 484 error: 3.200000\n",
      "DBscan took 0.0620 seconds\n",
      "CW:     people: 500 clusters: 453 error: 9.400000\n",
      "CW     took 5.1199 seconds\n",
      "----------------------------------------------\n",
      "Log of length 1000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 463 error: 7.400000\n",
      "DBscan took 0.1971 seconds\n",
      "CW:     people: 500 clusters: 453 error: 9.400000\n",
      "CW     took 16.2923 seconds\n",
      "----------------------------------------------\n",
      "Log of length 2500 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 470 error: 6.000000\n",
      "DBscan took 0.2695 seconds\n",
      "CW:     people: 500 clusters: 510 error: 2.000000\n",
      "CW     took 201.8060 seconds\n",
      "----------------------------------------------\n",
      "Log of length 4000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 466 error: 6.800000\n",
      "DBscan took 0.4905 seconds\n",
      "CW:     people: 500 clusters: 511 error: 2.200000\n",
      "CW     took 299.1070 seconds\n",
      "----------------------------------------------\n",
      "Log of length 5000 with 500 unique faces\n",
      "DBScan: people: 500 clusters: 461 error: 7.800000\n",
      "DBscan took 0.5784 seconds\n",
      "CW:     people: 500 clusters: 551 error: 10.200000\n",
      "CW     took 386.8930 seconds\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Fix log_length, vary n_people\n",
    "log_lengths = [500, 1000, 2500, 4000, 5000]\n",
    "n_peoples = 500\n",
    "\n",
    "epsilon = 9.8\n",
    "threshold = 72\n",
    "\n",
    "# Get data\n",
    "data_df = get_data(['lfw', 'cf'])\n",
    "\n",
    "for log_length in log_lengths:\n",
    "    # Generate log\n",
    "    log = generate_log(data_df, log_length=log_length, n_faces=n_peoples, exact=True).sample(frac=1).reset_index(drop=True)\n",
    "    n_people = len(log['id'].value_counts().keys())\n",
    "    print('Log of length %d with %d unique faces' % (len(log), n_people))\n",
    "        \n",
    "    # DBScan\n",
    "    X = log.drop(columns='id').values\n",
    "    # Do DBScan - Timed\n",
    "    db_start = time.perf_counter()\n",
    "    db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "    db_end = time.perf_counter()\n",
    "    labels = pd.Series(db.labels_)\n",
    "    db_n_clusters = len(list(labels.value_counts().values))\n",
    "    \n",
    "    # Chinese Whispers\n",
    "    log['randID'] = np.random.randint(100000, 999999, log.shape[0]).astype(str)\n",
    "    log['randID'] = log['id'] + log['randID']\n",
    "    d = log.drop(columns='id').set_index('randID').T.to_dict('list')\n",
    "    # Do Chinese Whispers - Timed\n",
    "    cw_start = time.perf_counter()\n",
    "    cw_clusters = do_chinese_whispers(d, threshold=threshold)\n",
    "    cw_end = time.perf_counter()\n",
    "    cw_n_clusters = len(cw_clusters.keys())\n",
    "\n",
    "    # Print results\n",
    "    db_est_err = estimation_error(n_clusters=db_n_clusters, n_people=n_people)\n",
    "    cw_est_err = estimation_error(n_clusters=cw_n_clusters, n_people=n_people)\n",
    "    \n",
    "    print('DBScan: people: %d clusters: %d error: %f' % (n_people, db_n_clusters, db_est_err))\n",
    "    print(f\"DBscan took {db_end - db_start:0.4f} seconds\")\n",
    "    \n",
    "    print('CW:     people: %d clusters: %d error: %f' % (n_people, cw_n_clusters, cw_est_err))\n",
    "    print(f\"CW     took {cw_end - cw_start:0.4f} seconds\") \n",
    "    print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ruled-thomson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 24517 images of 6743 different people \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e887d514e114>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlog_length\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlog_lengths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Generate log\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_faces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_peoples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mn_people\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Log of length %d with %d unique faces'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_people\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Univeristy\\diss\\AIaaS\\face\\notebooks\\GenerateLogs.ipynb\u001b[0m in \u001b[0;36mgenerate_log\u001b[1;34m(df, log_length, n_faces, exact)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;34m\"            df_subset = df[df['id'] == unique_id]\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;34m\"            \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[1;34m\"            # If more than one row randomly drop one row else skip\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m     \u001b[1;34m\"            if len(df_subset) > 1:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;34m\"                df = df.drop(labels=df_subset.sample(n=1).index, axis=0)\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Univeristy\\diss\\AIaaS\\face\\notebooks\\GenerateLogs.ipynb\u001b[0m in \u001b[0;36mresize_and_maintain_distribution\u001b[1;34m(df, n, exact)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;34m\"        exact: You want exactly n faces, if false, get roughly n faces and save a lot of time\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;34m\"        \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[1;34m\"        if      len(df) > log legnth: Keep distribution the same, remove a random image from each id (if count > 1), until log length = n\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[1;34m\"        else if len(df) < log length: Keep distribution the same, repeat a random image from each id, until log length = n\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;34m\"        else    log already of correct length\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sumaiyah\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2895\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sumaiyah\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2948\u001b[0m         \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2949\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2950\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2951\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fix log_length, vary n_people\n",
    "log_lengths = [5000, 10000, 25000, 40000, 50000]\n",
    "n_peoples = 5000\n",
    "\n",
    "epsilon = 9.8\n",
    "threshold = 72\n",
    "\n",
    "# Get data\n",
    "data_df = get_data(['lfw', 'cf'])\n",
    "\n",
    "for log_length in log_lengths:\n",
    "    # Generate log\n",
    "    log = generate_log(data_df, log_length=log_length, n_faces=n_peoples, exact=True).sample(frac=1).reset_index(drop=True)\n",
    "    n_people = len(log['id'].value_counts().keys())\n",
    "    print('Log of length %d with %d unique faces' % (len(log), n_people))\n",
    "        \n",
    "    # DBScan\n",
    "    X = log.drop(columns='id').values\n",
    "    # Do DBScan - Timed\n",
    "    db_start = time.perf_counter()\n",
    "    db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "    db_end = time.perf_counter()\n",
    "    labels = pd.Series(db.labels_)\n",
    "    db_n_clusters = len(list(labels.value_counts().values))\n",
    "    \n",
    "    # Chinese Whispers\n",
    "    log['randID'] = np.random.randint(100000, 999999, log.shape[0]).astype(str)\n",
    "    log['randID'] = log['id'] + log['randID']\n",
    "    d = log.drop(columns='id').set_index('randID').T.to_dict('list')\n",
    "    # Do Chinese Whispers - Timed\n",
    "    cw_start = time.perf_counter()\n",
    "    cw_clusters = do_chinese_whispers(d, threshold=threshold)\n",
    "    cw_end = time.perf_counter()\n",
    "    cw_n_clusters = len(cw_clusters.keys())\n",
    "\n",
    "    # Print results\n",
    "    db_est_err = estimation_error(n_clusters=db_n_clusters, n_people=n_people)\n",
    "    cw_est_err = estimation_error(n_clusters=cw_n_clusters, n_people=n_people)\n",
    "    \n",
    "    print('DBScan: people: %d clusters: %d error: %f' % (n_people, db_n_clusters, db_est_err))\n",
    "    print(f\"DBscan took {db_end - db_start:0.4f} seconds\")\n",
    "    \n",
    "    print('CW:     people: %d clusters: %d error: %f' % (n_people, cw_n_clusters, cw_est_err))\n",
    "    print(f\"CW     took {cw_end - cw_start:0.4f} seconds\") \n",
    "    print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-south",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
