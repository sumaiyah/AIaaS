{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dated-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ipynb.fs.full.GenerateLogs import generate_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pressing-richardson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 24517 images of 6743 different people\n"
     ]
    }
   ],
   "source": [
    "# Return ids of images in each dataset as a list\n",
    "def retrive_ids(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        ids = file.read().split()\n",
    "    return ids\n",
    "\n",
    "data_path = '../data/'\n",
    "names_path = lambda dataset_name: '%s%s-names.txt' % (data_path, dataset_name)\n",
    "embeddings_path = lambda dataset_name: '%s%s_embeddings.npz' % (data_path, dataset_name)\n",
    "\n",
    "datasets = ['lfw', 'cf']\n",
    "\n",
    "data_dfs = []\n",
    "for name in datasets:\n",
    "    data_df = pd.DataFrame(np.load(embeddings_path(name))['arr_0'])\n",
    "    data_df['id'] = retrive_ids(names_path(name))\n",
    "    data_dfs.append(data_df)\n",
    "    \n",
    "test_data_df = pd.concat(data_dfs).sample(frac=1).reset_index(drop=True)\n",
    "X = test_data_df.drop(columns='id').values\n",
    "# X = test_data_df.drop(columns='id').apply(lambda row : (row / np.linalg.norm(row)), axis = 1).values\n",
    "\n",
    "print('Dataset contains %s images of %s different people' % (len(test_data_df), len(test_data_df['id'].value_counts().keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ready-newman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Generating Log: len(df)=137, log_length=1000...Done.)\n",
      "Log of length 1000 with 50 unique faces\n",
      "eps: 9.800000, people: 50 clusters: 53 error: 6.000000\n",
      "\n",
      "(Generating Log: len(df)=354, log_length=1000...Done.)\n",
      "Log of length 1000 with 100 unique faces\n",
      "eps: 9.800000, people: 100 clusters: 103 error: 3.000000\n",
      "\n",
      "(Generating Log: len(df)=810, log_length=1000...Done.)\n",
      "Log of length 1000 with 250 unique faces\n",
      "eps: 9.800000, people: 250 clusters: 248 error: 0.800000\n",
      "\n",
      "(Generating Log: len(df)=1110, log_length=1000...Done.)\n",
      "Log of length 1000 with 400 unique faces\n",
      "eps: 9.800000, people: 400 clusters: 377 error: 5.750000\n",
      "\n",
      "(Generating Log: len(df)=1556, log_length=1000...Done.)\n",
      "Log of length 1000 with 500 unique faces\n",
      "eps: 9.800000, people: 500 clusters: 471 error: 5.800000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fix log_length, vary n_people\n",
    "log_length = 1000\n",
    "n_peoples = [50, 100, 250, 400, 500]\n",
    "epsilon = 9.8\n",
    "\n",
    "for n_people in n_peoples:\n",
    "    log = generate_log(test_data_df, log_length, n_people).sample(frac=1).reset_index(drop=True)\n",
    "    X = log.drop(columns='id').values\n",
    "    print('Log of length %d with %d unique faces' % (len(log), len(log['id'].value_counts().keys())))\n",
    "    \n",
    "    db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "    labels = pd.Series(db.labels_)\n",
    "\n",
    "    n_people = len(log['id'].value_counts().keys())\n",
    "    n_clusters = len(list(labels.value_counts().values))\n",
    "\n",
    "    est_error = (abs(n_clusters - n_people) / n_people) * 100\n",
    "    print('eps: %f, people: %d clusters: %d error: %f\\n' % (epsilon, n_people, n_clusters, est_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "american-release",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Generating Log: len(df)=2022, log_length=10000...Done.)\n",
      "Log of length 10000 with 500 unique faces\n",
      "eps: 9.800000, people: 500 clusters: 486 error: 2.800000\n",
      "\n",
      "(Generating Log: len(df)=3399, log_length=10000...Done.)\n",
      "Log of length 10000 with 1000 unique faces\n",
      "eps: 9.800000, people: 1000 clusters: 903 error: 9.700000\n",
      "\n",
      "(Generating Log: len(df)=8941, log_length=10000...Done.)\n",
      "Log of length 10000 with 2500 unique faces\n",
      "eps: 9.800000, people: 2500 clusters: 2094 error: 16.240000\n",
      "\n",
      "(Generating Log: len(df)=14487, log_length=10000...Done.)\n",
      "Log of length 10000 with 4000 unique faces\n",
      "eps: 9.800000, people: 4000 clusters: 3297 error: 17.575000\n",
      "\n",
      "(Generating Log: len(df)=18218, log_length=10000...Done.)\n",
      "Log of length 10000 with 5000 unique faces\n",
      "eps: 9.800000, people: 5000 clusters: 4172 error: 16.560000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fix log_length, vary n_people\n",
    "log_length = 10000\n",
    "n_peoples = [500, 1000, 2500, 4000, 5000]\n",
    "epsilon = 9.8\n",
    "\n",
    "for n_people in n_peoples:\n",
    "    log = generate_log(test_data_df, log_length, n_people).sample(frac=1).reset_index(drop=True)\n",
    "    X = log.drop(columns='id').values\n",
    "    print('Log of length %d with %d unique faces' % (len(log), len(log['id'].value_counts().keys())))\n",
    "    \n",
    "    db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "    labels = pd.Series(db.labels_)\n",
    "\n",
    "    n_people = len(log['id'].value_counts().keys())\n",
    "    n_clusters = len(list(labels.value_counts().values))\n",
    "\n",
    "    est_error = (abs(n_clusters - n_people) / n_people) * 100\n",
    "    print('eps: %f, people: %d clusters: %d error: %f\\n' % (epsilon, n_people, n_clusters, est_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "killing-cinema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Generating Log: len(df)=1754, log_length=25000...Done.)\n",
      "Log of length 25000 with 500 unique faces\n",
      "eps: 9.800000, people: 500 clusters: 473 error: 5.400000\n",
      "\n",
      "(Generating Log: len(df)=4172, log_length=25000...Done.)\n",
      "Log of length 25000 with 1000 unique faces\n",
      "eps: 9.800000, people: 1000 clusters: 882 error: 11.800000\n",
      "\n",
      "(Generating Log: len(df)=9060, log_length=25000...Done.)\n",
      "Log of length 25000 with 2500 unique faces\n",
      "eps: 9.800000, people: 2500 clusters: 2041 error: 18.360000\n",
      "\n",
      "(Generating Log: len(df)=14297, log_length=25000...Done.)\n",
      "Log of length 25000 with 4000 unique faces\n",
      "eps: 9.800000, people: 4000 clusters: 3142 error: 21.450000\n",
      "\n",
      "(Generating Log: len(df)=18335, log_length=25000...Done.)\n",
      "Log of length 25000 with 5000 unique faces\n",
      "eps: 9.800000, people: 5000 clusters: 3789 error: 24.220000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fix log_length, vary n_people\n",
    "log_length = 25000\n",
    "n_peoples = [500, 1000, 2500, 4000, 5000]\n",
    "epsilon = 9.8\n",
    "\n",
    "for n_people in n_peoples:\n",
    "    log = generate_log(test_data_df, log_length, n_people).sample(frac=1).reset_index(drop=True)\n",
    "    X = log.drop(columns='id').values\n",
    "    print('Log of length %d with %d unique faces' % (len(log), len(log['id'].value_counts().keys())))\n",
    "    \n",
    "    db = DBSCAN(eps=epsilon, min_samples=1).fit(X)\n",
    "    labels = pd.Series(db.labels_)\n",
    "\n",
    "    n_people = len(log['id'].value_counts().keys())\n",
    "    n_clusters = len(list(labels.value_counts().values))\n",
    "\n",
    "    est_error = (abs(n_clusters - n_people) / n_people) * 100\n",
    "    print('eps: %f, people: %d clusters: %d error: %f\\n' % (epsilon, n_people, n_clusters, est_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
