{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "republican-oliver",
   "metadata": {},
   "source": [
    "*Goal: Compare standard k-means clustering vs Time Series k-means clustering*\n",
    "\n",
    "Clustering is an unsupervised learning task where an algorithm groups similar data points with no 'ground truth' labels. \n",
    "Similarity between data points is measured with a distance metric, commonly Euclidean distance.\n",
    "Clustering different **time series** into similar groups is a challenging clustering task because **each data point is an ordered sequence**.\n",
    "\n",
    "The distance measures used in standard clustering algorithms, such as Euclidean distance, are often not appropriate to time series as it is invariant to time shifts. \n",
    "A better approach is to replace the default distance measure with a metric for comparing time series, such as **Dynamic Time Warping** \n",
    "\n",
    "[Explaination of DTW](http://alexminnaar.com/2014/04/16/Time-Series-Classification-and-Clustering-with-Python.html)\n",
    "Dynamic time warping finds the optimal non-linear alignment between two time series.\n",
    "The Euclidean distances between alignments are then much less susceptible to pessimistic similarity measurements due to distortion in the time axis. There is a price to pay for this, however, because dynamic time warping is **quadratic in the length of the time series used**.\n",
    "\n",
    "DTW is calculated as the **squared root of the sum of squared distances between each element in X and its nearest point in Y**. *Note that DTW(X, Y) â‰  DTW(Y, X)*\n",
    "\n",
    "With DTW, the centroids have an average shape that mimics the shape of the members of the cluster, regardless of where temporal shifts occur amongst the members.\n",
    "\n",
    "[dtw-kmeans](https://towardsdatascience.com/how-to-apply-k-means-clustering-to-time-series-data-28d04a8f7da3)\n",
    "*Note that tslearn expects a single time series to be formatted as two-dimensional array. A set of time series should be formatted as a three-dimensional array with shape (num_series, max_length, 1)*\n",
    "\n",
    "kmeans vs gmm vs dtw kmeans: then i can show that gmm gives decent clusters in a decent time frame so its the one i will choose to use from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "corrected-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\sumaiyah\\\\Documents\\\\Univeristy\\\\diss\\\\misuse-AIaaS')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "radio-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import filepaths\n",
    "from notebooks import FIC_60minute_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "disturbed-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "selected-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_df = pd.read_pickle(FIC_60minute_filepath(1)).drop(columns=[0,1,2,3])#.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smart-article",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fic_df = TimeSeriesScalerMeanVariance().fit_transform(fic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "processed-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=9\n",
    "clusters = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "assured-ceremony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46412, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "from tslearn.utils import to_time_series_dataset\n",
    "\n",
    "# Need values in specific shape for DTW\n",
    "dtw_vals = to_time_series_dataset(fic_df)\n",
    "print(dtw_vals.shape)\n",
    "\n",
    "sz = dtw_vals.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-thomas",
   "metadata": {},
   "source": [
    "# Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-springfield",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"DTW k-means k=%d\" % k)\n",
    "\n",
    "start = timer()\n",
    "model = TimeSeriesKMeans(n_clusters=k,\n",
    "                          metric=\"dtw\",\n",
    "                          verbose=False,\n",
    "                          random_state=42,\n",
    "                          n_jobs=3)\n",
    "dtw_kmeans_predictions = model.fit_predict(dtw_vals)\n",
    "end = timer()\n",
    "print('Clustering k=%d took %f seconds' % (k, (end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters['dtw_label'] = dtw_kmeans_predictions\n",
    "print(clusters['dtw_label'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-charity",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "civilian-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean k-means\n",
      "Clustering k=9 took 42.219677 seconds\n",
      "0    23195\n",
      "2     5813\n",
      "6     5096\n",
      "1     3135\n",
      "8     2147\n",
      "4     2031\n",
      "7     1797\n",
      "5     1753\n",
      "3     1445\n",
      "Name: kmeans_label, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Euclidean k-means\n",
    "print(\"Euclidean k-means\")\n",
    "\n",
    "start = timer()\n",
    "\n",
    "km = TimeSeriesKMeans(n_clusters=k, verbose=False, random_state=42)\n",
    "kmeans_predictions = km.fit_predict(dtw_vals)\n",
    "\n",
    "end = timer()\n",
    "print('Clustering k=%d took %f seconds' % (k, (end - start)))\n",
    "\n",
    "clusters['kmeans_label'] = kmeans_predictions\n",
    "print(clusters['kmeans_label'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-painting",
   "metadata": {},
   "source": [
    "# GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sublime-honduras",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of GMM Clustering with k=9\n",
      "Clustering k=9 took 19.359882 seconds\n",
      "7    13268\n",
      "6     9550\n",
      "5     5573\n",
      "4     4233\n",
      "8     3455\n",
      "1     2918\n",
      "0     2804\n",
      "3     2743\n",
      "2     1868\n",
      "Name: gmm_label, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "   \n",
    "print('Results of GMM Clustering with k=%d' % k)  \n",
    "\n",
    "start = timer()\n",
    "    \n",
    "# training gaussian mixture model \n",
    "gmm = GaussianMixture(n_components=k, random_state=42, init_params='random')\n",
    "gmm.fit(dtw_vals[:,:,0])\n",
    "gmm_labels = gmm.predict(dtw_vals[:,:,0])\n",
    "    \n",
    "end = timer()\n",
    "\n",
    "print('Clustering k=%d took %f seconds' % (k, (end - start)))\n",
    "clusters['gmm_label'] = gmm_labels\n",
    "print(clusters['gmm_label'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-economics",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-major",
   "metadata": {},
   "source": [
    "# DTW Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "provincial-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print each cluster in order of size from largest cluster to smallest\n",
    "# cluster_order = pd.Series(dtw_kmeans_predictions).value_counts().keys().tolist()\n",
    "\n",
    "# fig, ax = plt.subplots(3, 3, figsize=(12, 10), sharex=True, sharey=True)\n",
    "\n",
    "# fig.text(0.5, 0, 'Time (hours)', ha='center', fontsize=14)\n",
    "# fig.text(0, 0.5, 'ln(function invocation count)', va='center', rotation='vertical', fontsize=14)\n",
    "# fig.suptitle(\"DTW $k$-means\")\n",
    "\n",
    "\n",
    "# for yi in range(len(cluster_order)):\n",
    "#     row, col = yi // 3, yi % 3\n",
    "#     cluster_index = cluster_order[yi]\n",
    "    \n",
    "#     for xx in dtw_vals[dtw_kmeans_predictions == yi]:\n",
    "#         ax[row, col].plot(xx.ravel(), \"k-\", alpha=.05)\n",
    "#         ax[row, col].plot(model.cluster_centers_[cluster_index].ravel(), \"r-\")\n",
    "        \n",
    "#     ax[row, col].text(16, -4.5, \n",
    "#                       'Cluster %d \\n size:%d' % ((yi + 1), pd.Series(dtw_kmeans_predictions).value_counts().values[yi]),\n",
    "#                       color=\"#95190C\",\n",
    "#                       fontsize=13)\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# plt.savefig('dtwkm.png', dpi=500)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-equity",
   "metadata": {},
   "source": [
    "# k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each cluster in order of size from largest cluster to smallest\n",
    "cluster_order = pd.Series(kmeans_predictions).value_counts().keys().tolist()\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(12, 10), sharex=True, sharey=True)\n",
    "\n",
    "fig.text(0.5, 0, 'Time (hours)', ha='center', fontsize=14)\n",
    "fig.text(0, 0.5, 'ln(function invocation count)', va='center', rotation='vertical', fontsize=14)\n",
    "fig.suptitle(\"Euclidian $k$-means\")\n",
    "\n",
    "for yi in range(len(cluster_order)):\n",
    "    row, col = yi // 3, yi % 3\n",
    "    cluster_index = cluster_order[yi]\n",
    "    \n",
    "    for xx in dtw_vals[kmeans_predictions == cluster_index]:\n",
    "        ax[row, col].plot(xx.ravel(), \"k-\", alpha=.05)\n",
    "        ax[row, col].plot(km.cluster_centers_[cluster_index].ravel(), \"r-\")\n",
    "\n",
    "    ax[row, col].text(16, -4.5, \n",
    "                      'Cluster %d \\nSize:%d' % ((yi + 1), pd.Series(kmeans_predictions).value_counts().values[yi]),\n",
    "                      color=\"#95190C\",\n",
    "                      fontsize=13, \n",
    "                      weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('kmm.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-hartford",
   "metadata": {},
   "source": [
    "# GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# https://stackoverflow.com/questions/47412749/how-can-i-get-a-representative-point-of-a-gmm-cluster\n",
    "centers = np.empty(shape=(gmm.n_components, dtw_vals[:,:,0].shape[1]))\n",
    "for i in range(gmm.n_components):\n",
    "    density = scipy.stats.multivariate_normal(cov=gmm.covariances_[i], mean=gmm.means_[i]).logpdf(dtw_vals[:,:,0])\n",
    "    centers[i, :] = dtw_vals[:,:,0][np.argmax(abs(density))]\n",
    "\n",
    "# Print each cluster in order of size from largest cluster to smallest\n",
    "cluster_order = pd.Series(gmm_labels).value_counts().keys().tolist()\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(12, 10), sharex=True, sharey=True)\n",
    "\n",
    "fig.text(0.5, 0, 'Time (hours)', ha='center', fontsize=14)\n",
    "fig.text(0, 0.5, 'ln(function invocation count)', va='center', rotation='vertical', fontsize=14)\n",
    "fig.suptitle(\"Gaussian mixture model\")\n",
    "\n",
    "for yi in range(len(cluster_order)):\n",
    "    row, col = yi // 3, yi % 3\n",
    "    cluster_index = cluster_order[yi]\n",
    "    \n",
    "    for xx in dtw_vals[gmm_labels == cluster_index]:\n",
    "        ax[row, col].plot(xx.ravel(), \"k-\", alpha=.01)\n",
    "        ax[row, col].plot(centers[cluster_index].ravel(), \"r-\")\n",
    "\n",
    "    ax[row, col].text(16, -4.5, \n",
    "                      'Cluster %d \\nSize:%d' % ((yi + 1), pd.Series(gmm_labels).value_counts().values[yi]),\n",
    "                      color=\"#95190C\",\n",
    "                      fontsize=13, \n",
    "                      weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gmm.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-butterfly",
   "metadata": {},
   "source": [
    "| Clustering Algorithm           | Cluster Sizes                                           | Clustering Time (s) |\n",
    "|--------------------------------|---------------------------------------------------------|---------------------|\n",
    "| Gaussian Mixture Model         | [13268, 9550, 5573, 4233, 3455, 2918, 2804, 2743, 1868] | 16.121              |\n",
    "| Euclidean $K$-means            | [23195, 5813, 5096, 3135, 2147, 2031, 1797, 1753, 1445] | 53.384              |\n",
    "| Dynamic Time Warping $K$-means | [11970, 11740, 6175, 5048, 3627, 3064, 2159, 1753, 876] | 1876.661            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-adams",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
